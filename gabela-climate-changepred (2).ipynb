{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-11T11:30:21.075260Z",
     "iopub.status.busy": "2021-10-11T11:30:21.072650Z",
     "iopub.status.idle": "2021-10-11T11:30:21.086875Z",
     "shell.execute_reply": "2021-10-11T11:30:21.085804Z",
     "shell.execute_reply.started": "2021-10-11T11:30:21.075171Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Installing Libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-11T11:30:21.101764Z",
     "iopub.status.busy": "2021-10-11T11:30:21.101137Z",
     "iopub.status.idle": "2021-10-11T11:30:21.111334Z",
     "shell.execute_reply": "2021-10-11T11:30:21.110634Z",
     "shell.execute_reply.started": "2021-10-11T11:30:21.101716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-5.3.1-py2.py3-none-any.whl (23.9 MB)\n",
      "Requirement already satisfied: six in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from plotly) (1.15.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.3.1 tenacity-8.0.1\n",
      "Collecting stopwordsiso\n",
      "  Downloading stopwordsiso-0.6.1-py3-none-any.whl (73 kB)\n",
      "Installing collected packages: stopwordsiso\n",
      "Successfully installed stopwordsiso-0.6.1\n",
      "Collecting yellowbrick\n",
      "  Downloading yellowbrick-1.3.post1-py3-none-any.whl (271 kB)\n",
      "Requirement already satisfied: cycler>=0.10.0 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from yellowbrick) (0.10.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from yellowbrick) (0.23.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from yellowbrick) (1.5.2)\n",
      "Requirement already satisfied: numpy<1.20,>=1.16.0 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from yellowbrick) (1.19.2)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from yellowbrick) (3.3.2)\n",
      "Requirement already satisfied: six in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from cycler>=0.10.0->yellowbrick) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20->yellowbrick) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20->yellowbrick) (2.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (8.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2020.6.20)\n",
      "Installing collected packages: yellowbrick\n",
      "Successfully installed yellowbrick-1.3.post1\n",
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.8.1-py3-none-any.whl (189 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.19.2)\n",
      "Collecting scikit-learn>=0.24\n",
      "  Downloading scikit_learn-1.0-cp38-cp38-win_amd64.whl (7.2 MB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
      "Installing collected packages: scikit-learn, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.23.2\n",
      "    Uninstalling scikit-learn-0.23.2:\n",
      "      Successfully uninstalled scikit-learn-0.23.2\n",
      "Successfully installed imbalanced-learn-0.8.1 imblearn-0.0 scikit-learn-1.0\n"
     ]
    }
   ],
   "source": [
    "# Download packages\n",
    "!pip install plotly\n",
    "!pip install stopwordsiso\n",
    "!pip install yellowbrick\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.1-cp38-cp38-win_amd64.whl (155 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from wordcloud) (8.0.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from wordcloud) (1.19.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from wordcloud) (3.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2020.6.20)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ngabela\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.15.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-11T11:30:21.113294Z",
     "iopub.status.busy": "2021-10-11T11:30:21.112881Z",
     "iopub.status.idle": "2021-10-11T11:30:21.126472Z",
     "shell.execute_reply": "2021-10-11T11:30:21.125455Z",
     "shell.execute_reply.started": "2021-10-11T11:30:21.113247Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from yellowbrick.text import FreqDistVisualizer\n",
    "from yellowbrick.features import RadViz\n",
    "from wordcloud import WordCloud\n",
    "import plotly.io as pio\n",
    "%matplotlib inline\n",
    "\n",
    "#noise libaries \n",
    "import re\n",
    "import string \n",
    "from stopwordsiso import stopwords as sw\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Text Preprocessing\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# Feature Engineering and Data preparation for modelling\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Model building and training\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Model evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#save the final model and vectorizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-11T11:30:21.128519Z",
     "iopub.status.busy": "2021-10-11T11:30:21.127764Z",
     "iopub.status.idle": "2021-10-11T11:30:21.200526Z",
     "shell.execute_reply": "2021-10-11T11:30:21.199474Z",
     "shell.execute_reply.started": "2021-10-11T11:30:21.128482Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train = pd.read_csv('../input/edsa-climate-change-belief-analysis-2021/train.csv')\n",
    "# Visualize the first ten rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-11T11:30:21.203235Z",
     "iopub.status.busy": "2021-10-11T11:30:21.202822Z",
     "iopub.status.idle": "2021-10-11T11:30:21.245790Z",
     "shell.execute_reply": "2021-10-11T11:30:21.243995Z",
     "shell.execute_reply.started": "2021-10-11T11:30:21.203186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test = pd.read_csv('../input/edsa-climate-change-belief-analysis-2021/test.csv')\n",
    "# Visualize the first ten rows\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Text Preprocessing - cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-11T11:30:21.247383Z",
     "iopub.status.busy": "2021-10-11T11:30:21.247044Z",
     "iopub.status.idle": "2021-10-11T11:30:21.256119Z",
     "shell.execute_reply": "2021-10-11T11:30:21.255195Z",
     "shell.execute_reply.started": "2021-10-11T11:30:21.247339Z"
    }
   },
   "outputs": [],
   "source": [
    "#dataframe cleaning function\n",
    "def text_preprocessing (dataframe):\n",
    "    \n",
    "    \n",
    "    numercial_digits = r'\\d+'\n",
    "    twitter_handles = r'@(\\w+)'\n",
    "    url_address = r'(https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}[-a-zA-Z0-9()@:%_+.~#?&/=]*)'\n",
    "        \n",
    "    \n",
    "    #create copy to perform cleaning on df\n",
    "    dataframe = dataframe.copy()\n",
    "    \n",
    "    #covert to lowercaps in message col\n",
    "    low = lambda tweets: ''.join([tweet.lower() for tweet in tweets])\n",
    "    dataframe['message'] =dataframe['message'].apply(low) # The low function is used convert values in the message column to lowercase\n",
    "    \n",
    "    #remove punctuation in message col\n",
    "    punct = lambda tweets: ''.join([tweet for tweet in tweets if tweet not in string.punctuation])\n",
    "    dataframe['message'] = dataframe['message'].apply(punct)# The punct function is used ot remove punctuation from the message column\n",
    "    \n",
    "    #remove non-ascii characters in message col\n",
    "    dataframe.message.replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)\n",
    "    \n",
    "    #remove website addresses in message col\n",
    "    dataframe['message'] = dataframe['message'].replace(to_replace = url_address, value = '', regex = True)\n",
    "    \n",
    "    #remove numercial values in message col\n",
    "    dataframe['message'] = dataframe['message'].replace(to_replace = numercial_digits, value = '', regex = True)\n",
    "    \n",
    "    #remove twitter handles in message col\n",
    "    dataframe['message'] = dataframe['message'].replace(to_replace = twitter_handles, value = '', regex = True)\n",
    "   \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-11T11:30:21.257613Z",
     "iopub.status.busy": "2021-10-11T11:30:21.257238Z",
     "iopub.status.idle": "2021-10-11T11:30:21.885725Z",
     "shell.execute_reply": "2021-10-11T11:30:21.884793Z",
     "shell.execute_reply.started": "2021-10-11T11:30:21.257573Z"
    }
   },
   "outputs": [],
   "source": [
    "#return training dataset from dataframe \n",
    "cleaned_train = text_preprocessing(train)\n",
    "\n",
    "#show the first 8 rows of the cleaned train dataframe and show width for the message col\n",
    "with pd.option_context('display.max_colwidth', 200):\n",
    "    display(cleaned_train.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Stopwords removal and tokenisation(tzr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-11T11:30:21.887639Z",
     "iopub.status.busy": "2021-10-11T11:30:21.887139Z",
     "iopub.status.idle": "2021-10-11T11:30:21.893062Z",
     "shell.execute_reply": "2021-10-11T11:30:21.892386Z",
     "shell.execute_reply.started": "2021-10-11T11:30:21.887600Z"
    }
   },
   "outputs": [],
   "source": [
    "#function that tokenizes words on df\n",
    "def tokens(dataframe, column_name):\n",
    "    \n",
    "   #create copy to perform tokenization on df\n",
    "    dataframe = dataframe.copy()\n",
    "    \n",
    "   #to remove redundant lettering in words using - reduce_len\n",
    "    tzr = TweetTokenizer(reduce_len = True)\n",
    "    \n",
    "    dataframe[column_name] = dataframe[column_name].apply(tzr.tokenize)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-11T11:30:21.894945Z",
     "iopub.status.busy": "2021-10-11T11:30:21.894450Z",
     "iopub.status.idle": "2021-10-11T11:30:22.780133Z",
     "shell.execute_reply": "2021-10-11T11:30:22.779268Z",
     "shell.execute_reply.started": "2021-10-11T11:30:21.894906Z"
    }
   },
   "outputs": [],
   "source": [
    "#return the cleaned training dataset dataframe and message column using the tokens func\n",
    "token_train = tokens(cleaned_train, 'message')\n",
    "\n",
    "#show the first 8 rows of the cleaned train dataframe and show width for the message col\n",
    "with pd.option_context('display.max_colwidth', 200):\n",
    "    display(token_train.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-11T11:30:22.783741Z",
     "iopub.status.busy": "2021-10-11T11:30:22.783376Z",
     "iopub.status.idle": "2021-10-11T11:30:22.789899Z",
     "shell.execute_reply": "2021-10-11T11:30:22.789323Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.783707Z"
    }
   },
   "outputs": [],
   "source": [
    "#funct that removes stop words and \"rt\" from df \n",
    "def stop(dataframe, column_name):\n",
    "   \n",
    "    #create copy to perform stopwords on df\n",
    "    dataframe = dataframe.copy()\n",
    "    \n",
    "    # funct that returns tokenized words which are not 'rt'\n",
    "    rt = lambda tweets: [tweet for tweet in tweets if tweet != 'rt']\n",
    "    \n",
    "    # funct that removes all 'rt'instances on df\n",
    "    dataframe[column_name] = dataframe[column_name].apply(rt)\n",
    "    \n",
    "    #funct that returns the words in a tokenized df that do not appear in a stopwords set\n",
    "    stops = lambda tweets: [tweet for tweet in tweets if tweet not in stopwords('english')]\n",
    "    \n",
    "    #funct removing all stopwords on the specified column,\n",
    "    dataframe[column_name] = dataframe[column_name].apply(stops)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-11T11:30:22.791632Z",
     "iopub.status.busy": "2021-10-11T11:30:22.791138Z",
     "iopub.status.idle": "2021-10-11T11:30:22.957849Z",
     "shell.execute_reply": "2021-10-11T11:30:22.954129Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.791592Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call the stop function on the tokenized training dataset dataframe, creating a new training dataframe without stopwords and rts\n",
    "stops_train = stop(token_train, 'message')\n",
    "\n",
    "# Display the first 10 rows of the training dataframe without stopwords and rts, allowing maximum width for the message column\n",
    "with pd.option_context('display.max_colwidth', 400):\n",
    "    display(stops_train.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Lemmatizaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.958897Z",
     "iopub.status.idle": "2021-10-11T11:30:22.959356Z",
     "shell.execute_reply": "2021-10-11T11:30:22.959200Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.959183Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#create a new dataframe to be lemmatized(train)\n",
    "lemmatized_train = stop_train.copy()\n",
    "\n",
    "#use lemmatizer on the message col of the train dataframe\n",
    "lemmatized_train['message'] = stop_train['message'].apply(lambda sentence : [lemmatizer.lemmatize(word) for word in sentence])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.960202Z",
     "iopub.status.idle": "2021-10-11T11:30:22.960623Z",
     "shell.execute_reply": "2021-10-11T11:30:22.960473Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.960457Z"
    }
   },
   "outputs": [],
   "source": [
    "#show the first 8 rows of the train dataframe and show width for the message col\n",
    "with pd.option_context('display.max_colwidth', 200):\n",
    "    display(lemmatized_train.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.961397Z",
     "iopub.status.idle": "2021-10-11T11:30:22.961807Z",
     "shell.execute_reply": "2021-10-11T11:30:22.961671Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.961655Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a new dataframe to be lemmatized(test)\n",
    "lemmatized_test = stop_test.copy()\n",
    "\n",
    "#use lemmatizer on the message column of the test dataframe\n",
    "lemmatized_test['message'] = stop_test['message'].apply(lambda sentence: [lemmatizer.lemmatize(word) for word in sentence])\n",
    "\n",
    "#show the first 8 rows of the test dataframe and show width for the message col\n",
    "with pd.option_context('display.max_colwidth', 200):\n",
    "    display(lemmatized_test.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.962695Z",
     "iopub.status.idle": "2021-10-11T11:30:22.963157Z",
     "shell.execute_reply": "2021-10-11T11:30:22.963015Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.962997Z"
    }
   },
   "outputs": [],
   "source": [
    "#combine the tokenized words and lemmatized_train message col a sentence\n",
    "lemmatized_train['message'] = [' '.join(tweet) for tweet in lemmatized_train['message'].values]\n",
    "\n",
    "#show the first 8 rows of the train dataframe and show width for the message col\n",
    "with pd.option_context('display.max_colwidth', 400):\n",
    "    display(lemmatized_train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.963939Z",
     "iopub.status.idle": "2021-10-11T11:30:22.964343Z",
     "shell.execute_reply": "2021-10-11T11:30:22.964195Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.964180Z"
    }
   },
   "outputs": [],
   "source": [
    "#combine the tokenized words and lemmatized_test message col a sentence \n",
    "lemmatized_test['message'] = [' '.join(tweet) for tweet in lemmatized_test['message'].values]\n",
    "\n",
    "#show the first 8 rows of the train dataframe and show width for the message col\n",
    "with pd.option_context('display.max_colwidth', 200):\n",
    "    display(lemmatized_test.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Predictor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.965109Z",
     "iopub.status.idle": "2021-10-11T11:30:22.965520Z",
     "shell.execute_reply": "2021-10-11T11:30:22.965378Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.965363Z"
    }
   },
   "outputs": [],
   "source": [
    "#funct extracting hashtags from df\n",
    "def hashtag_extract(message):\n",
    "   \n",
    "    #creat an empty list to be used to gather hashtag\n",
    "    hashtag = []\n",
    "    \n",
    "    #In every word in message col find words that start with '#'(hashtag)\n",
    "    for tweet in message: \n",
    "        hasht = re.findall(r\"#(\\w+)\", tweet) \n",
    "        hashtag.append(hasht) \n",
    "        \n",
    "    return hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.966335Z",
     "iopub.status.idle": "2021-10-11T11:30:22.966801Z",
     "shell.execute_reply": "2021-10-11T11:30:22.966636Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.966612Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the hashtags extract function to get hashtags associated with the positive class from the original training dataframe\n",
    "positive_hashtag = hashtag_extract(train['message'][train['sentiment'] == 1])\n",
    "\n",
    "# Use the hashtags extract function to get hashtags associated with the negative class from the original training dataframe\n",
    "negative_hashtag = hashtag_extract(train['message'][train['sentiment'] == -1])\n",
    "\n",
    "# Use the hashtags extract function to get hashtags associated with the neutral class from the original training dataframe\n",
    "neutral_hashtag = hashtag_extract(train['message'][train['sentiment'] == 0])\n",
    "\n",
    "# Use the hashtags extract function to get hashtags associated with the news class from the original training dataframe\n",
    "news_hashtag = hashtag_extract(train['message'][train['sentiment'] == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.967650Z",
     "iopub.status.idle": "2021-10-11T11:30:22.968210Z",
     "shell.execute_reply": "2021-10-11T11:30:22.967913Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.967893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a single list for the positive sentiment\n",
    "positive_hashtags = sum(positive_hashtags, [])\n",
    "\n",
    "# Create a single list for the negative sentiment\n",
    "negative_hashtags = sum(negative_hashtags, [])\n",
    "\n",
    "# Create a single list for the neutral sentiment\n",
    "neutral_hashtags = sum(neutral_hashtags, [])\n",
    "\n",
    "# Create a single list for the news sentiment\n",
    "news_hashtags = sum(news_hashtags, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.969126Z",
     "iopub.status.idle": "2021-10-11T11:30:22.969606Z",
     "shell.execute_reply": "2021-10-11T11:30:22.969424Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.969402Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a distribution plot of the most frequent hashtags in the positive hashtags list \n",
    "freq = nltk.FreqDist(positive_hashtags)\n",
    "\n",
    "# Create a dataframe from the result of the frequency distribution plot, using the hashtags in one column and frequencies\n",
    "# in a second\n",
    "df = pd.DataFrame({'Hashtags' : list(freq.keys()),\n",
    "                   'Count' : list(freq.values())})\n",
    "\n",
    "# Sort the hashtags by order of descending counts and show the first 10 rows i.e the 10 most frequent hashtags\n",
    "df_pos = df.sort_values(by = 'Count', ascending = False)\n",
    "df_pos.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.970452Z",
     "iopub.status.idle": "2021-10-11T11:30:22.970925Z",
     "shell.execute_reply": "2021-10-11T11:30:22.970758Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.970735Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a bar plot using the group dataframe  to visualise the number of tweets per class\n",
    "fig = go.Figure(go.Bar(x = df_pos['Hashtags'].head(10), \n",
    "                       y = df_pos['Count'].head(10).sort_values(ascending = False), # Specify x and y variables\n",
    "                       marker = {'color': df_pos['Count'],'colorscale': 'viridis'})) # Select a colour for the graph\n",
    "\n",
    "# Add title, x and y axis labels to the bar chart\n",
    "fig.update_layout(yaxis_title = 'Hashtag Counts', xaxis_title = 'Hashtags', \n",
    "                  title = 'Count of Hashtags for Positive Man-Made Climate Change Sentiment')\n",
    "\n",
    "# Show the bar plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.971759Z",
     "iopub.status.idle": "2021-10-11T11:30:22.972194Z",
     "shell.execute_reply": "2021-10-11T11:30:22.972020Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.972003Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a distribution plot of the most frequent hashtags in the negative hashtags list\n",
    "freq = nltk.FreqDist(negative_hashtags)\n",
    "\n",
    "# Create a dataframe the results of the frequency distribution plot , using the hashtags in the one column and frequencies\n",
    "# in a second\n",
    "df = pd.DataFrame({'Hashtags' : list(freq.keys()),\n",
    "                   'Count' : list(freq.values())})\n",
    "\n",
    "# Sort the hashtags by order descending counts and show the first 10 rows i.e the 10 most frequent hashtags\n",
    "df_neg = df.sort_values(by = 'Count', ascending = False)\n",
    "df_neg.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.973039Z",
     "iopub.status.idle": "2021-10-11T11:30:22.973518Z",
     "shell.execute_reply": "2021-10-11T11:30:22.973310Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.973291Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a bar plot using the group dataframe  to visualise the number of tweets per class\n",
    "fig = go.Figure(go.Bar(x = df_neg['Hashtags'].head(10), \n",
    "                       y = df_neg['Count'].head(10).sort_values(ascending = False), # Specify x and y variables\n",
    "                       marker = {'color': df_neg['Count'],'colorscale': 'viridis'})) # Select a colour for the graph\n",
    "\n",
    "# Add title, x and y axis labels to the bar chart\n",
    "fig.update_layout(yaxis_title = 'Hashtag Counts', xaxis_title = 'Hashtags', \n",
    "                  title = 'Count of Hashtags for Negative Man-Made Climate Change Sentiment')\n",
    "\n",
    "# Show the bar plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.974408Z",
     "iopub.status.idle": "2021-10-11T11:30:22.974881Z",
     "shell.execute_reply": "2021-10-11T11:30:22.974711Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.974689Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a distribution plot of the most frequent hashtags in neutral hashtags list\n",
    "freq = nltk.FreqDist(neutral_hashtags)\n",
    "\n",
    "# Create a dataframe the results of the frequency distribution plot, using the hashtags in the one column and frequencies\n",
    "# in a second\n",
    "df = pd.DataFrame({'Hashtags' : list(freq.keys()),\n",
    "                   'Count' : list(freq.values())})\n",
    "# Sort the hashtags by order descending counts and show the first 10 rows i.e the 10 most frequent hashtags\n",
    "df_neu = df.sort_values(by = \"Count\", ascending = False)\n",
    "df_neu.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.975731Z",
     "iopub.status.idle": "2021-10-11T11:30:22.976248Z",
     "shell.execute_reply": "2021-10-11T11:30:22.976014Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.975992Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a bar plot using the group dataframe  to visualise the number of tweets per class\n",
    "fig = go.Figure(go.Bar(x = df_neu['Hashtags'].head(10), \n",
    "                       y = df_neu['Count'].head(10).sort_values(ascending = False), # Specify x and y variables\n",
    "                       marker = {'color': df_neu['Count'],'colorscale': 'viridis'})) # Select a colour for the graph\n",
    "\n",
    "# Add title, x and y axis labels to the bar chart\n",
    "fig.update_layout(yaxis_title = 'Hashtag Counts', xaxis_title = 'Hashtags', \n",
    "                  title = 'Count of Hashtags for Neutral Man-Made Climate Change Sentiment')\n",
    "\n",
    "# Show the bar plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.977138Z",
     "iopub.status.idle": "2021-10-11T11:30:22.977612Z",
     "shell.execute_reply": "2021-10-11T11:30:22.977420Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.977398Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a distribution plot of the most frequent hashtags in news hashtags list\n",
    "freq = nltk.FreqDist(news_hashtags)\n",
    "\n",
    "# Create a dataframe the results of the frequency distribution plot, using the hashtags in the one column and frequencies\n",
    "# in a second\n",
    "df = pd.DataFrame({'Hashtags' : list(freq.keys()),\n",
    "                   'Count' : list(freq.values())})\n",
    "\n",
    "# Sort the hashtags by order descending counts and show the first 10 rows i.e the 10 most frequent hashtags\n",
    "df_news = df.sort_values(by = 'Count', ascending = False)\n",
    "df_news.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.978460Z",
     "iopub.status.idle": "2021-10-11T11:30:22.978926Z",
     "shell.execute_reply": "2021-10-11T11:30:22.978759Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.978736Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a bar plot using the group dataframe  to visualise the number of tweets per class\n",
    "fig = go.Figure(go.Bar(x = df_news['Hashtags'].head(10), \n",
    "                       y = df_news['Count'].head(10), # Specify x and y variables\n",
    "                       marker = {'color': df_news['Count'],'colorscale': 'viridis'})) # Select a colour for the graph\n",
    "\n",
    "# Add title, x and y axis labels to the bar chart\n",
    "fig.update_layout(yaxis_title = 'Hashtag Counts', xaxis_title = 'Hashtags', \n",
    "                  title = 'Count of Hashtags for News Climate Change Sentiment')\n",
    "\n",
    "# Show the bar plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.979777Z",
     "iopub.status.idle": "2021-10-11T11:30:22.980210Z",
     "shell.execute_reply": "2021-10-11T11:30:22.980045Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.980023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the clean, preprocessed training data in order to visualise the most frequently use non-stopword words for each sentiment\n",
    "\n",
    "# Create function to exclude subject matter words such as climate, change, global, and warming\n",
    "extractor = lambda words:  \" \".join([word for word in words.split() if word not in climate_list])\n",
    "\n",
    "# Extract, from the training dataset, all the tweets written by individuals who were pro man-made climate change\n",
    "data_pos = lemmatized_train[lemmatized_train['sentiment'] == 1] \n",
    "data_pos = data_pos['message'].apply(extractor) # Extract the message column which holds just the tweets in this sentiment\n",
    "\n",
    "# Extract, from the training dataset, all the tweets written by individuals who were anti man-made climate change\n",
    "data_neg = lemmatized_train[lemmatized_train['sentiment'] == -1]\n",
    "data_neg = data_neg['message'].apply(extractor)# Extract the message column which holds just the tweets in this sentiment\n",
    "\n",
    "# Extract, from the training dataset, all the tweets written by individuals who were neutral on man-made climate change\n",
    "data_neutral = lemmatized_train[lemmatized_train['sentiment'] == 0]\n",
    "data_neutral = data_neutral['message'].apply(extractor) # Extract the message column which holds just the tweets in this sentiment\n",
    "\n",
    "# Extract, from the training dataset, all the tweets related to news about climate change\n",
    "data_news = lemmatized_train[lemmatized_train['sentiment'] == 2]\n",
    "data_news = data_news['message'].apply(extractor) # Extract the message column which holds just the tweets in this sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.981106Z",
     "iopub.status.idle": "2021-10-11T11:30:22.981593Z",
     "shell.execute_reply": "2021-10-11T11:30:22.981405Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.981375Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer as cv_pos\n",
    "cv_pos = CountVectorizer()\n",
    "docs_pos = cv_pos.fit_transform(data_pos) # Fit cv_pos to the series containing tweets associated with the positive sentiment\n",
    "features_pos = cv_pos.get_feature_names() # Get the words used in the positive sentiment\n",
    "\n",
    "# Instantiate CountVectorizer as cv_neg\n",
    "cv_neg = CountVectorizer()\n",
    "docs_neg = cv_neg.fit_transform(data_neg) # Fit cv_neg to the series containing tweets associated with the negative sentiment\n",
    "features_neg = cv_neg.get_feature_names()# Get the words used in the negative sentiment\n",
    "\n",
    "# Instantiate CountVectorizer as cv_neutral\n",
    "cv_neutral = CountVectorizer()\n",
    "# Fit cv_neutral to the series containing tweets associated with the neutral sentiment\n",
    "docs_neutral = cv_neutral.fit_transform(data_neutral)  \n",
    "features_neutral = cv_neutral.get_feature_names() # Get words used in the neutral sentiment\n",
    "\n",
    "# Instantiate CountVectorizer as cv_news\n",
    "cv_news = CountVectorizer()\n",
    "docs_news = cv_news.fit_transform(data_news) # Fit cv_news to the series containing tweets associated with the news sentiment\n",
    "features_news = cv_news.get_feature_names() # Get words used in the negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.982470Z",
     "iopub.status.idle": "2021-10-11T11:30:22.982943Z",
     "shell.execute_reply": "2021-10-11T11:30:22.982777Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.982755Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a frequency distribution plot to display the most frequent words associated with the positive sentiment\n",
    "viz_pos = FreqDistVisualizer(features = features_pos, orient = 'v', n = 5, color = 'green',\n",
    "                            title = 'Frequency Distribution of Top 10 tokens for Pro sentiment')\n",
    "#Enlargen the plot\n",
    "visualizer_pos = RadViz(classes = docs_pos, features = features_pos, size = (1080, 720))\n",
    "\n",
    "# Fit the vectorized bag of words to the instantiated frequency distribution plot\n",
    "viz_pos.fit(docs_pos)\n",
    "viz_pos.show() # Display the graph of positive sentiment words\n",
    "\n",
    "# Create a frequency distribution plot to display the most frequent words associated with the negative sentiment\n",
    "viz_neg = FreqDistVisualizer(features = features_neg, orient = 'v', n = 5, color = 'red',\n",
    "                            title = 'Frequency Distribution of Top 10 tokens for Anti sentiment')\n",
    "# Enlargen the plot\n",
    "visualizer_pos = RadViz(classes = docs_pos, features = features_pos, size = (1080, 720))\n",
    "\n",
    "# Fit the vectorized bag of words to the instantiated frequency distribution plot\n",
    "viz_neg.fit(docs_neg)\n",
    "viz_neg.show() # Display the graph of negative sentiment words\n",
    "\n",
    "# Create a frequency distribution plot to display the most frequent words associated with the neutral sentiment\n",
    "viz_neutral = FreqDistVisualizer(features = features_neutral, orient = 'v', n = 5, color = 'yellow',\n",
    "                                title = 'Frequency Distribution of Top 10 tokens for Neutral sentiment')\n",
    "#Enalargen the plot\n",
    "visualizer_neutral = RadViz(classes = docs_pos, features = features_pos, size = (1080, 720))\n",
    "\n",
    "# Fit the vectorized bag of words to the instantiated frequency distribution plot\n",
    "viz_neutral.fit(docs_neutral)\n",
    "viz_neutral.show() # Display the graph of neutral sentiment words\n",
    "\n",
    "# Create a frequency distribution plot to display the most frequent words associated with the news sentiment\n",
    "viz_news = FreqDistVisualizer(features = features_news, orient = 'v', n = 5, color = 'purple',\n",
    "                             title = 'Frequency Distribution of Top 10 tokens for News class')\n",
    "# Enlargen the plot\n",
    "visualizer_pnews = RadViz(classes = docs_pos, features = features_pos, size = (1080, 720))\n",
    "\n",
    "# Fit the vectorized bag of words to the instantiated frequency distribution plot\n",
    "viz_news.fit(docs_news)\n",
    "viz_news.show() # Display the graph of news sentiment words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Label Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.983858Z",
     "iopub.status.idle": "2021-10-11T11:30:22.984301Z",
     "shell.execute_reply": "2021-10-11T11:30:22.984126Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.984104Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe by grouping tweets by sentiment and counting the number of tweets in each sentiment\n",
    "group = lemmatized_train.groupby('sentiment').count()['message'].reset_index().sort_values(by = 'message', ascending = False)\n",
    "\n",
    "# Display the new dataframe.  The sentiment column displays the four classes, \n",
    "# while the message column display the number of tweets per class\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.985163Z",
     "iopub.status.idle": "2021-10-11T11:30:22.985646Z",
     "shell.execute_reply": "2021-10-11T11:30:22.985450Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.985429Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a bar plot using the group dataframe  to visualise the number of tweets per class\n",
    "fig = go.Figure(go.Bar(x = ['Positive', 'News', 'Neutral', 'Negative'],y = group['message'], # Specify x and y variables\n",
    "                       marker = {'color': group['message'],'colorscale': 'plasma'})) # Select a colour for the graph\n",
    "\n",
    "# Add title, x and y axis labels to the bar chart\n",
    "fig.update_layout(yaxis_title = 'Tweets', xaxis_title = 'Sentiment', title = 'Number of Tweets Per Sentiment')\n",
    "\n",
    "# Show the bar plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.986494Z",
     "iopub.status.idle": "2021-10-11T11:30:22.986965Z",
     "shell.execute_reply": "2021-10-11T11:30:22.986806Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.986784Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a funnel chart indicating the numbers of tweets per class as a proportion\n",
    "fig = go.Figure(go.Funnelarea(text = ['Positive', 'News', 'Neutral', 'Negative'], values = group['message'], \n",
    "                              marker = {'colors': group['message']}, # column to colour chart on\n",
    "                              title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}, # Chart Title\n",
    "                              labels = ['Positive', 'News', 'Neutral', 'Negative'])) # Legend labels\n",
    "\n",
    "# Show the funnel chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.987880Z",
     "iopub.status.idle": "2021-10-11T11:30:22.988327Z",
     "shell.execute_reply": "2021-10-11T11:30:22.988151Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.988129Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collect tweets from the lemmatized_train dataframe written by pro man-made climate change individuals\n",
    "positive_words = \" \".join([sentence for sentence in lemmatized_train['message'][lemmatized_train['sentiment'] == 1]])\n",
    "\n",
    "# Instantiate  the wordcloud and use positive_words to generate a wordcloud for the 'pro' sentiment\n",
    "positive_wordcloud = WordCloud(width = 800, height = 500, random_state = 42, max_font_size = 100, \n",
    "                               background_color = 'white').generate(positive_words)\n",
    "\n",
    "# Plot the positive wordcloud on an empty axis and use plt.show() to display it\n",
    "ax1 = plt.imshow(positive_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Collect tweets from the lemmatized_train dataframe written by anti man-made climate change individuals\n",
    "negative_words = \" \".join([sentence for sentence in lemmatized_train['message'][lemmatized_train['sentiment'] == -1]])\n",
    "\n",
    "# Instantiate the wordcloud  and use negative_words to generate a wordcloud for the anti sentiment\n",
    "negative_wordcloud = WordCloud(width = 800, height = 500, random_state = 42, max_font_size = 100, \n",
    "                               background_color = 'white').generate(negative_words)\n",
    "\n",
    "# Plot the negative wordcloud on an empty axis and use plt.show() to display it\n",
    "ax2 = plt.imshow(negative_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Collect tweets from the lemmatized_train dataframe written by individuals with neutral views on man-made climate change\n",
    "neutral_words = \" \".join([sentence for sentence in lemmatized_train['message'][lemmatized_train['sentiment'] == 0]])\n",
    "\n",
    "# Instantiate the wordcloud and use neutral words to generate a wordcloud for the neutral sentiment\n",
    "neutral_wordcloud = WordCloud(width = 800, height = 500, random_state = 42, max_font_size = 100, \n",
    "                              background_color = 'white').generate(neutral_words)\n",
    "\n",
    "# Plot the neutral wordcloud on an empty axis and use plt.show() to display it\n",
    "ax3 = plt.imshow(neutral_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Collect tweets from the lemmatized_train dataframe that link to actual news stories related to climate change\n",
    "news_words = \" \".join([sentence for sentence in lemmatized_train['message'][lemmatized_train['sentiment'] == 2]])\n",
    "\n",
    "# Instantiate wordcloud and use news_words to generate a wordcloud for the news\n",
    "news_wordcloud = WordCloud(width = 800, height = 500, random_state = 42, max_font_size = 100, \n",
    "                           background_color = 'white').generate(news_words)\n",
    "\n",
    "# Plot the news wordcloud on an empty axis and use plt.show() to display it\n",
    "ax4 = plt.imshow(news_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.989249Z",
     "iopub.status.idle": "2021-10-11T11:30:22.989737Z",
     "shell.execute_reply": "2021-10-11T11:30:22.989554Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.989518Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of the four most frequent words in the wordclouds\n",
    "climate_list = ['climate', 'change', 'global', 'warming']\n",
    "\n",
    "# Collect tweets from positive_words excluding the frequent words from the wordclouds\n",
    "new_positive = \" \".join([word for word in positive_words.split() if word not in climate_list])\n",
    "\n",
    "# Instantiate  the wordcloud and use positive_words to generate a wordcloud for the 'pro' sentiment\n",
    "pos_wc = WordCloud(width = 800, height = 500, random_state = 42, max_font_size = 100, \n",
    "                   background_color = 'white').generate(new_positive)\n",
    "\n",
    "# Plot the positive wordcloud on an empty axis and use plt.show() to display it\n",
    "ax1 = plt.imshow(pos_wc)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Collect tweets from negative_words excluding the frequent words from the wordclouds\n",
    "new_negative = \" \".join([word for word in negative_words.split() if word not in climate_list])\n",
    "\n",
    "# Instantiate the wordcloud  and use negative_words to generate a wordcloud for the anti sentiment\n",
    "neg_wc = WordCloud(width = 800, height = 500, random_state = 42, max_font_size = 100, \n",
    "                               background_color = 'white').generate(new_negative)\n",
    "\n",
    "# Plot the negative wordcloud on an empty axis and use plt.show() to display it\n",
    "ax2 = plt.imshow(neg_wc)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Collect tweets from neutral_words excluding the frequent words from the wordclouds\n",
    "new_neutral = \" \".join([word for word in neutral_words.split() if word not in climate_list])\n",
    "\n",
    "# Instantiate the wordcloud and use neutral words to generate a wordcloud for the neutral sentiment\n",
    "neu_wc = WordCloud(width = 800, height = 500, random_state = 42, max_font_size = 100, \n",
    "                              background_color = 'white').generate(new_neutral)\n",
    "\n",
    "# Plot the neutral wordcloud on an empty axis and use plt.show() to display it\n",
    "ax3 = plt.imshow(neu_wc)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Collect tweets from news_words excluding the frequent words from the wordclouds\n",
    "new_news = \" \".join([word for word in news_words.split() if word not in climate_list])\n",
    "\n",
    "# Instantiate wordcloud and use news_words to generate a wordcloud for the news\n",
    "new_wc = WordCloud(width = 800, height = 500, random_state = 42, max_font_size = 100, \n",
    "                           background_color = 'white').generate(new_news)\n",
    "\n",
    "# Plot the news wordcloud on an empty axis and use plt.show() to display it\n",
    "ax4 = plt.imshow(new_wc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.990715Z",
     "iopub.status.idle": "2021-10-11T11:30:22.991176Z",
     "shell.execute_reply": "2021-10-11T11:30:22.991005Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.990980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function that cleans the training data and prepares it for modelling\n",
    "def preprocessing(string):\n",
    "    \"\"\"This function takes a sentence and transforms it to lowercase using the lower() string method, it then removed urls,\n",
    "       numerical values, punctuation, and rts (retweets) using regex patterns.  The function also use TweetTokenizer from the\n",
    "       nltk.tokenize library in order to remove twitter handles\n",
    "       \n",
    "       Parameters\n",
    "       ----------\n",
    "       string : str\n",
    "           A sentence string which is to go through text cleaning\n",
    "           \n",
    "       Returns\n",
    "       -------\n",
    "       str\n",
    "           A string which has been cleaned of noise\"\"\"\n",
    "    \n",
    "    # Change the casing in the inputted string to lowercase\n",
    "    string = string.lower()\n",
    "    \n",
    "    # Remove url addresses from the string\n",
    "    string = re.sub(r\"http\\S+\", \"\", string)\n",
    "    \n",
    "    # Instantiate TweetTokenizer with an argument that allows for the stripping of twitter handles\n",
    "    tknzr = TweetTokenizer(strip_handles = True)\n",
    "    \n",
    "    # Tokenize the string using TweetTokenizer in order to remove twitter handles\n",
    "    string = tknzr.tokenize(string)\n",
    "    \n",
    "    # Join the tokenized words together into sentences \n",
    "    string = \" \".join(string)\n",
    "    \n",
    "    # Remove punctuation from the string \n",
    "    string = re.sub(r'[^a-z0-9\\s]', '', string)\n",
    "    string = re.sub(r'[0-9]+', '', string) # replace numbers or number like words with 'number'\n",
    "    \n",
    "    # Remove rt from the string\n",
    "    message = re.sub(r'^rt', '', string)\n",
    "    \n",
    "    # Return a new string which has been cleaned of noise\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.996871Z",
     "iopub.status.idle": "2021-10-11T11:30:22.997314Z",
     "shell.execute_reply": "2021-10-11T11:30:22.997118Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.997090Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a copy our the training data set, train_data, which will be used to build the models\n",
    "train_data = train.copy()\n",
    "\n",
    "# Call the created function preprocessing on train_data dataframe message column in order to clear the tweets of noise \n",
    "train_data['message']= train_data['message'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:22.998429Z",
     "iopub.status.idle": "2021-10-11T11:30:22.999247Z",
     "shell.execute_reply": "2021-10-11T11:30:22.999058Z",
     "shell.execute_reply.started": "2021-10-11T11:30:22.999035Z"
    }
   },
   "outputs": [],
   "source": [
    "# The label, y, is defined as the sentiment column in the dataframe, train_data\n",
    "y = train_data.sentiment\n",
    "\n",
    "# The predictors, X, are defined as the message column in the dataframe, train_data\n",
    "predictors = train_data.message \n",
    "\n",
    "# View the shape of the label and predictors\n",
    "print(predictors.shape) # predictors\n",
    "print(y.shape) # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.000360Z",
     "iopub.status.idle": "2021-10-11T11:30:23.000981Z",
     "shell.execute_reply": "2021-10-11T11:30:23.000801Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.000779Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer with the ngrams argument as cv\n",
    "cv = CountVectorizer(ngram_range =(1,2))\n",
    "\n",
    "# Use cv to vectorize the text data in the message columnn of the dataframe, creating a new vector, X\n",
    "X = cv.fit_transform(predictors)\n",
    "\n",
    "# View the shape of vectorized the sparse matrix\n",
    "print(\"The predictors have the shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.002126Z",
     "iopub.status.idle": "2021-10-11T11:30:23.002761Z",
     "shell.execute_reply": "2021-10-11T11:30:23.002582Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.002557Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train test split is called on the variables X and y to create a training and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.003935Z",
     "iopub.status.idle": "2021-10-11T11:30:23.004525Z",
     "shell.execute_reply": "2021-10-11T11:30:23.004355Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.004334Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the shape of the X training variable, X_train \n",
    "print(f'The X training variable has the shape: {X_train.shape}')\n",
    "\n",
    "# Print the shape of the y training variable, y_train\n",
    "print(f'The y training variable has the shape: {y_train.shape}')\n",
    "\n",
    "# Print the shape of the X validation variable, X_val\n",
    "print(f'The X validation variable has the shape: {X_val.shape}')\n",
    "\n",
    "#Print the shape of the y validation variable, y_val\n",
    "print(f'The y validation variable has the shape: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.005703Z",
     "iopub.status.idle": "2021-10-11T11:30:23.006562Z",
     "shell.execute_reply": "2021-10-11T11:30:23.006356Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.006330Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model as logreg\n",
    "logreg = LogisticRegression(multi_class = 'ovr', solver = 'liblinear', random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.007589Z",
     "iopub.status.idle": "2021-10-11T11:30:23.007913Z",
     "shell.execute_reply": "2021-10-11T11:30:23.007763Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.007743Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model to our training data\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.009449Z",
     "iopub.status.idle": "2021-10-11T11:30:23.010277Z",
     "shell.execute_reply": "2021-10-11T11:30:23.010086Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.010063Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "y_logreg = logreg.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1. Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Accuracy Metrics Used\n",
    "- Confusion Matrix\n",
    "- Classification Report\n",
    "- F1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.011316Z",
     "iopub.status.idle": "2021-10-11T11:30:23.011661Z",
     "shell.execute_reply": "2021-10-11T11:30:23.011496Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.011475Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the labels to be used in the confusion matrix\n",
    "# Confusion matrix\n",
    "true_labels = ['true : Anti', 'true : Neutral', 'true : Pro', 'true : News']\n",
    "pred_labels = ['pred : Anti', 'pred : Neutral', 'pred : Pro', 'pred : News']\n",
    "type_labels = ['-1 : Anti', '0 : Neutral', '1 : Pro', '2 : News']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.012912Z",
     "iopub.status.idle": "2021-10-11T11:30:23.013232Z",
     "shell.execute_reply": "2021-10-11T11:30:23.013085Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.013064Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the confusion matrix dataframe to visualise the number of correctly predicted observations\n",
    "pd.DataFrame(data = confusion_matrix(y_val, y_logreg), index = true_labels, columns = pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.014067Z",
     "iopub.status.idle": "2021-10-11T11:30:23.014387Z",
     "shell.execute_reply": "2021-10-11T11:30:23.014239Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.014213Z"
    }
   },
   "outputs": [],
   "source": [
    "#A classification report shows the precision, recall and f1 scores of the model's performance\n",
    "# Create a classification report from the validation set\n",
    "logreg_report = classification_report(y_val, y_logreg, target_names=type_labels)\n",
    "\n",
    "# Print out the classification report \n",
    "print(logreg_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.015126Z",
     "iopub.status.idle": "2021-10-11T11:30:23.015438Z",
     "shell.execute_reply": "2021-10-11T11:30:23.015289Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.015267Z"
    }
   },
   "outputs": [],
   "source": [
    "#f1 score\n",
    "f1_score_logreg = f1_score(y_val,y_logreg,average =\"weighted\") \n",
    "print(f'This is the accuracy for the basic LogisticRegression classifier: {f1_score_logreg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. SMOTE Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.016243Z",
     "iopub.status.idle": "2021-10-11T11:30:23.016590Z",
     "shell.execute_reply": "2021-10-11T11:30:23.016413Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.016392Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate SMOTE as sm\n",
    "sm = SMOTE(random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.018206Z",
     "iopub.status.idle": "2021-10-11T11:30:23.018534Z",
     "shell.execute_reply": "2021-10-11T11:30:23.018390Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.018370Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the SMOTE model on the training data\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.019882Z",
     "iopub.status.idle": "2021-10-11T11:30:23.020194Z",
     "shell.execute_reply": "2021-10-11T11:30:23.020051Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.020030Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate a Logistic Regression model to use with the resampled data as logreg_smote \n",
    "logreg_smote = LogisticRegression(multi_class = 'ovr', solver = 'liblinear', random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.021427Z",
     "iopub.status.idle": "2021-10-11T11:30:23.021758Z",
     "shell.execute_reply": "2021-10-11T11:30:23.021611Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.021589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the logistic regression model on the resampled data\n",
    "logreg_smote.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.022505Z",
     "iopub.status.idle": "2021-10-11T11:30:23.022834Z",
     "shell.execute_reply": "2021-10-11T11:30:23.022687Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.022666Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the validation set\n",
    "y_logreg_smote = logreg_smote.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.2. Model Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.023626Z",
     "iopub.status.idle": "2021-10-11T11:30:23.024000Z",
     "shell.execute_reply": "2021-10-11T11:30:23.023839Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.023770Z"
    }
   },
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "# Create a confusion matrix on the validation data\n",
    "pd.DataFrame(data = confusion_matrix(y_val, y_logreg_smote), index = true_labels, columns = pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.025089Z",
     "iopub.status.idle": "2021-10-11T11:30:23.025411Z",
     "shell.execute_reply": "2021-10-11T11:30:23.025268Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.025248Z"
    }
   },
   "outputs": [],
   "source": [
    "#classification report\n",
    "#classification report on the validation set\n",
    "smote_report = classification_report(y_val, y_logreg_smote, target_names = type_labels)\n",
    "\n",
    "# Print the classification report\n",
    "print(smote_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.026068Z",
     "iopub.status.idle": "2021-10-11T11:30:23.026351Z",
     "shell.execute_reply": "2021-10-11T11:30:23.026217Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.026202Z"
    }
   },
   "outputs": [],
   "source": [
    "#f1 score\n",
    "# Calcuate the f1 score on the validation set\n",
    "f1_score_logreg_smote = f1_score(y_val, y_logreg_smote, average = \"weighted\")\n",
    "\n",
    "# Print the f1 score\n",
    "print(f'This is the accuracy for the basic LogisticRegression classifier: {f1_score_logreg_smote}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.027421Z",
     "iopub.status.idle": "2021-10-11T11:30:23.027773Z",
     "shell.execute_reply": "2021-10-11T11:30:23.027607Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.027591Z"
    }
   },
   "outputs": [],
   "source": [
    "# comparison basic logistic regression model vs the smote logistic regression model\n",
    "# Create a dataframe to show the f1 scores of the basic logistic regression model vs the smote logistic regression model\n",
    "\n",
    "# Create a list of f1 scores\n",
    "f1_scores = [f1_score_logreg, f1_score_logreg_smote]\n",
    "\n",
    "# Create a list to use as row labels\n",
    "models = [\"logreg(no smote)\",\"logreg(with smote)\"] \n",
    "\n",
    "# Create metric column name list\n",
    "metrics = ['f1_score']\n",
    "\n",
    "# Create the dataframe\n",
    "model_df = pd.DataFrame(data = f1_scores, index = models, columns = metrics)\n",
    "\n",
    "# Display the first 5 rows of the new dataframe\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  7.3. Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.028787Z",
     "iopub.status.idle": "2021-10-11T11:30:23.029068Z",
     "shell.execute_reply": "2021-10-11T11:30:23.028940Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.028925Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the support vector classifier model as svm_clf \n",
    "svm_clf = SVC(C = 10, gamma = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.029845Z",
     "iopub.status.idle": "2021-10-11T11:30:23.030122Z",
     "shell.execute_reply": "2021-10-11T11:30:23.029993Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.029980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.033932Z",
     "iopub.status.idle": "2021-10-11T11:30:23.034395Z",
     "shell.execute_reply": "2021-10-11T11:30:23.034244Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.034225Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the validation set\n",
    "y_svm_CV = svm_clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 7.2.1. Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.035070Z",
     "iopub.status.idle": "2021-10-11T11:30:23.035849Z",
     "shell.execute_reply": "2021-10-11T11:30:23.035675Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.035655Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe to display the confusion matrix results\n",
    "pd.DataFrame(data = confusion_matrix(y_val, y_svm_CV), index = true_labels, columns = pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.036910Z",
     "iopub.status.idle": "2021-10-11T11:30:23.037479Z",
     "shell.execute_reply": "2021-10-11T11:30:23.037317Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.037298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the classification report the validation set\n",
    "print(classification_report(y_val, y_svm_CV, target_names = type_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.038275Z",
     "iopub.status.idle": "2021-10-11T11:30:23.038815Z",
     "shell.execute_reply": "2021-10-11T11:30:23.038654Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.038635Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the f1 score on the validation set\n",
    "f1_score_svm = f1_score(y_val, y_svm_CV, average = \"weighted\") \n",
    "\n",
    "# Print the f1 score\n",
    "print(f'This is the accuracy for the basic Support Vector Machine classifier: {f1_score_svm}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. SMOTE Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.039515Z",
     "iopub.status.idle": "2021-10-11T11:30:23.039897Z",
     "shell.execute_reply": "2021-10-11T11:30:23.039740Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.039718Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate a support vector classifier model to use on the resampled data\n",
    "svm_clf_CV_smote = SVC(C = 10, gamma = 0.01)\n",
    "\n",
    "# Fit the model on the resampled data\n",
    "svm_clf_CV_smote.fit(X_res,y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.040842Z",
     "iopub.status.idle": "2021-10-11T11:30:23.041116Z",
     "shell.execute_reply": "2021-10-11T11:30:23.040988Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.040974Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict using the validation set\n",
    "y_pred_svm_CV_smote = svm_clf_CV_smote.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.1. Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.042229Z",
     "iopub.status.idle": "2021-10-11T11:30:23.043048Z",
     "shell.execute_reply": "2021-10-11T11:30:23.042876Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.042855Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe to display the confusion matrix results\n",
    "pd.DataFrame(data = confusion_matrix(y_val, y_pred_svm_CV_smote), index = true_labels, columns = pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.044172Z",
     "iopub.status.idle": "2021-10-11T11:30:23.044848Z",
     "shell.execute_reply": "2021-10-11T11:30:23.044674Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.044652Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the classification report the validation set\n",
    "print(classification_report(y_val, y_pred_svm_CV_smote, target_names = type_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.045779Z",
     "iopub.status.idle": "2021-10-11T11:30:23.046301Z",
     "shell.execute_reply": "2021-10-11T11:30:23.046150Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.046132Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the f1 score on the validation set\n",
    "f1_svm_CV_smote = f1_score(y_val, y_pred_svm_CV_smote, average = \"weighted\") \n",
    "\n",
    "# Print the f1 score\n",
    "print(f'This is the accuracy for the basic Support Vector Machine classifier: {f1_score_svm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.047190Z",
     "iopub.status.idle": "2021-10-11T11:30:23.047749Z",
     "shell.execute_reply": "2021-10-11T11:30:23.047606Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.047584Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe to show the f1 scores of the basic support vector classifier model vs the smote support vector classifier\n",
    "# model\n",
    "\n",
    "# Create a list of f1 scores\n",
    "f1_scores = [f1_score_svm, f1_svm_CV_smote]\n",
    "\n",
    "# Create a list to use as row labels\n",
    "models = [\"svc(no smote)\",\"svc(with smote)\"] \n",
    "\n",
    "# Create metric column name list\n",
    "metrics = ['f1_score']\n",
    "\n",
    "# Create the dataframe\n",
    "model_df = pd.DataFrame(data = f1_scores, index = models, columns = metrics)\n",
    "\n",
    "# Display the first 5 rows of the new dataframe\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.048654Z",
     "iopub.status.idle": "2021-10-11T11:30:23.049292Z",
     "shell.execute_reply": "2021-10-11T11:30:23.049136Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.049109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the naive bayes model as nb\n",
    "nb = MultinomialNB() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.050463Z",
     "iopub.status.idle": "2021-10-11T11:30:23.051017Z",
     "shell.execute_reply": "2021-10-11T11:30:23.050841Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.050822Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.051778Z",
     "iopub.status.idle": "2021-10-11T11:30:23.052509Z",
     "shell.execute_reply": "2021-10-11T11:30:23.052327Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.052305Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the validation data\n",
    "pred_nb = nb.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.1. Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.053351Z",
     "iopub.status.idle": "2021-10-11T11:30:23.053684Z",
     "shell.execute_reply": "2021-10-11T11:30:23.053494Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.053481Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe to display the confusion matrix results\n",
    "pd.DataFrame(data = confusion_matrix(y_val, pred_nb), index = true_labels, columns = pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.054618Z",
     "iopub.status.idle": "2021-10-11T11:30:23.054894Z",
     "shell.execute_reply": "2021-10-11T11:30:23.054767Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.054753Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the classification on the validation set\n",
    "print(classification_report(y_val, pred_nb, target_names = type_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.055533Z",
     "iopub.status.idle": "2021-10-11T11:30:23.055819Z",
     "shell.execute_reply": "2021-10-11T11:30:23.055694Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.055680Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the f1 score on the validation set\n",
    "f1_nb = f1_score(y_val, pred_nb, average = \"weighted\") \n",
    "\n",
    "# Print the f1 score\n",
    "print(f'This is the accuracy for the Naive Bayes classifier: {f1_score_svm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4. SMOTE Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.057950Z",
     "iopub.status.idle": "2021-10-11T11:30:23.058705Z",
     "shell.execute_reply": "2021-10-11T11:30:23.058504Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.058476Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the naive bayes classifier as nb_smote to use on the resampled data\n",
    "nb_smote = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.059889Z",
     "iopub.status.idle": "2021-10-11T11:30:23.060474Z",
     "shell.execute_reply": "2021-10-11T11:30:23.060301Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.060281Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model on the resampled data\n",
    "nb_smote.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.061682Z",
     "iopub.status.idle": "2021-10-11T11:30:23.062563Z",
     "shell.execute_reply": "2021-10-11T11:30:23.062372Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.062344Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict of the validation set\n",
    "pred_nbsmote = nb_smote.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4.1. Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.063401Z",
     "iopub.status.idle": "2021-10-11T11:30:23.063935Z",
     "shell.execute_reply": "2021-10-11T11:30:23.063774Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.063755Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe to display the confusion matrix results\n",
    "pd.DataFrame(data = confusion_matrix(y_val, pred_nbsmote), index = true_labels, columns = pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.064657Z",
     "iopub.status.idle": "2021-10-11T11:30:23.065479Z",
     "shell.execute_reply": "2021-10-11T11:30:23.065289Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.065268Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the classification report of the validation set\n",
    "print(classification_report(y_val, pred_nbsmote, target_names = type_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.066603Z",
     "iopub.status.idle": "2021-10-11T11:30:23.067267Z",
     "shell.execute_reply": "2021-10-11T11:30:23.067054Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.067025Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the f1 score on the validation set\n",
    "f1_nb_smote = f1_score(y_val, pred_nbsmote, average = \"weighted\") \n",
    "\n",
    "# Print the f1 score\n",
    "print(f'This is the accuracy for the Naive Bayes classifier: {f1_score_svm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.068017Z",
     "iopub.status.idle": "2021-10-11T11:30:23.068330Z",
     "shell.execute_reply": "2021-10-11T11:30:23.068170Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.068156Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe to show the f1 scores of the Naive Bayes classifier model vs the smote Naive Bayes classifier\n",
    "# model\n",
    "\n",
    "# Create a list of f1 scores\n",
    "f1_scores = [f1_nb, f1_nb_smote]\n",
    "\n",
    "# Create a list to use as row labels\n",
    "models = [\"NB (no smote)\",\"NB (with smote)\"] \n",
    "\n",
    "# Create metric column name list\n",
    "metrics = ['f1_score']\n",
    "\n",
    "# Create the dataframe\n",
    "model_df = pd.DataFrame(data = f1_scores, index = models, columns = metrics)\n",
    "\n",
    "# Display the first 5 rows of the new dataframe\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.069010Z",
     "iopub.status.idle": "2021-10-11T11:30:23.069300Z",
     "shell.execute_reply": "2021-10-11T11:30:23.069161Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.069146Z"
    }
   },
   "outputs": [],
   "source": [
    "# define classifiers that we'll apply cross validation to\n",
    "clf1 = logreg\n",
    "clf2 = svm_clf\n",
    "clf3 = nb\n",
    "\n",
    "# create empty list where we'll append the f1 score's mean and std of each classifier obtained through cross validation\n",
    "cross_val = []\n",
    "\n",
    "# loop through list of classifiers and apply cross_val_score function\n",
    "for clf, label in zip([clf1,clf2,clf3],['Logistic Regresion','SVM', 'Naive Bayes']):\n",
    "    print(label)\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring = 'f1_micro')\n",
    "    print(\"f1 score: {:0.4f} (+/- {:0.4f})\".format(scores.mean(), scores.std()))\n",
    "    cross_val.append([label, scores.mean(), scores.std() ]) # append the scores to the empty list created abov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.070019Z",
     "iopub.status.idle": "2021-10-11T11:30:23.070324Z",
     "shell.execute_reply": "2021-10-11T11:30:23.070180Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.070166Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert list of cv scores to dataframe\n",
    "cross_val = pd.DataFrame(cross_val, columns=['Model', 'CV_Mean', 'CV_Std_Dev'])\n",
    "cross_val.set_index('Model', inplace=True) # set index to the name of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.071248Z",
     "iopub.status.idle": "2021-10-11T11:30:23.071569Z",
     "shell.execute_reply": "2021-10-11T11:30:23.071412Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.071398Z"
    }
   },
   "outputs": [],
   "source": [
    "# view our dataframe containing cross valiation mean and std\n",
    "cross_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.072288Z",
     "iopub.status.idle": "2021-10-11T11:30:23.072586Z",
     "shell.execute_reply": "2021-10-11T11:30:23.072439Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.072425Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a copy of the test to perform noise cleaning and vectorization on\n",
    "test_data = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.073382Z",
     "iopub.status.idle": "2021-10-11T11:30:23.073710Z",
     "shell.execute_reply": "2021-10-11T11:30:23.073533Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.073519Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call the data cleaning function the test_data dataframe to remove noise in preparation for cleaning\n",
    "test_data['message'] = test_data['message'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.074419Z",
     "iopub.status.idle": "2021-10-11T11:30:23.074775Z",
     "shell.execute_reply": "2021-10-11T11:30:23.074600Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.074577Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use CountVector in order to encode the words in the clean test dataframe\n",
    "test_cv_trans =  cv.transform(test_data['message'])\n",
    "\n",
    "# Print out the shape of the newly vectorized dataframe\n",
    "print(\"The shape of the data is:\", test_cv_trans.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.075449Z",
     "iopub.status.idle": "2021-10-11T11:30:23.075755Z",
     "shell.execute_reply": "2021-10-11T11:30:23.075614Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.075600Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict on test_data\n",
    "y_pred_logreg_sub = logreg.predict(test_cv_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.1. Logistic Regression Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.076523Z",
     "iopub.status.idle": "2021-10-11T11:30:23.076819Z",
     "shell.execute_reply": "2021-10-11T11:30:23.076689Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.076675Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the tweetid column from test_data to use as the submission file index\n",
    "tweetid = test_data['tweetid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.077529Z",
     "iopub.status.idle": "2021-10-11T11:30:23.077858Z",
     "shell.execute_reply": "2021-10-11T11:30:23.077716Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.077701Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe using the test_data tweetid and and the predicted sentiment\n",
    "submission_logreg = pd.DataFrame({'tweetid' : tweetid, 'sentiment' : y_pred_logreg_sub})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.080108Z",
     "iopub.status.idle": "2021-10-11T11:30:23.081060Z",
     "shell.execute_reply": "2021-10-11T11:30:23.080882Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.080861Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the last 5 rows of the submission file\n",
    "submission_logreg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.082862Z",
     "iopub.status.idle": "2021-10-11T11:30:23.083504Z",
     "shell.execute_reply": "2021-10-11T11:30:23.083344Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.083326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file for submission\n",
    "submission_logreg.to_csv(\"AM3_logreg_predictions.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.084811Z",
     "iopub.status.idle": "2021-10-11T11:30:23.085108Z",
     "shell.execute_reply": "2021-10-11T11:30:23.084976Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.084961Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict on test_data\n",
    "y_pred_svm_sub = svm_clf.predict(test_cv_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.1 Support Vector Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.086412Z",
     "iopub.status.idle": "2021-10-11T11:30:23.087159Z",
     "shell.execute_reply": "2021-10-11T11:30:23.086983Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.086963Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe using the test_data tweetid and and the predicted sentiment\n",
    "submission_svc = pd.DataFrame({'tweetid' : tweetid, 'sentiment' : y_pred_svm_sub})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.088039Z",
     "iopub.status.idle": "2021-10-11T11:30:23.088622Z",
     "shell.execute_reply": "2021-10-11T11:30:23.088453Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.088433Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the last 5 rows of the submission file\n",
    "submission_svc.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.089784Z",
     "iopub.status.idle": "2021-10-11T11:30:23.090840Z",
     "shell.execute_reply": "2021-10-11T11:30:23.090636Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.090586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file for submission\n",
    "submission_svc.to_csv(\"AM3_SVC_predictions.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.091682Z",
     "iopub.status.idle": "2021-10-11T11:30:23.092512Z",
     "shell.execute_reply": "2021-10-11T11:30:23.092322Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.092300Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_nb = nb.predict(test_cv_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.1. Naive Bayes Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.093468Z",
     "iopub.status.idle": "2021-10-11T11:30:23.094176Z",
     "shell.execute_reply": "2021-10-11T11:30:23.093983Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.093957Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe using the test_data tweetid and and the predicted sentiment\n",
    "submission_nb = pd.DataFrame({'tweetid' : tweetid, 'sentiment' : y_pred_nb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.095298Z",
     "iopub.status.idle": "2021-10-11T11:30:23.096205Z",
     "shell.execute_reply": "2021-10-11T11:30:23.096024Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.096003Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the last 5 rows of the submission file\n",
    "submission_nb.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.096947Z",
     "iopub.status.idle": "2021-10-11T11:30:23.097864Z",
     "shell.execute_reply": "2021-10-11T11:30:23.097694Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.097675Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file for submission\n",
    "submission_nb.to_csv(\"AM3_nb_predictions.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1. Model Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.098575Z",
     "iopub.status.idle": "2021-10-11T11:30:23.099490Z",
     "shell.execute_reply": "2021-10-11T11:30:23.099297Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.099274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on the train set\n",
    "train_pred_logreg = logreg.predict(X_train)\n",
    "f1_score_train_logreg = f1_score(y_train,train_pred_logreg,average = \"weighted\") # Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.100197Z",
     "iopub.status.idle": "2021-10-11T11:30:23.101019Z",
     "shell.execute_reply": "2021-10-11T11:30:23.100831Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.100809Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the validation set\n",
    "train_pred_logreg_smote = logreg_smote.predict(X_train) # Train_set\n",
    "f1_score_train_logreg_smote =f1_score(y_train,train_pred_logreg_smote,average = \"weighted\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.101920Z",
     "iopub.status.idle": "2021-10-11T11:30:23.102483Z",
     "shell.execute_reply": "2021-10-11T11:30:23.102332Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.102315Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the train set \n",
    "train_pred_svm_CV = svm_clf.predict(X_train)\n",
    "# Calculate the f1 score on the train set\n",
    "f1_score_train_svm = f1_score(y_train, train_pred_svm_CV,average = \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.103452Z",
     "iopub.status.idle": "2021-10-11T11:30:23.104205Z",
     "shell.execute_reply": "2021-10-11T11:30:23.103854Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.103832Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict using the validation set\n",
    "train_pred_svm_smote = svm_clf_CV_smote.predict(X_train)\n",
    "# Calculate the f1 score on the train set\n",
    "f1_score_train_svm_smote = f1_score(y_train,train_pred_svm_smote, average = \"weighted\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.105298Z",
     "iopub.status.idle": "2021-10-11T11:30:23.105850Z",
     "shell.execute_reply": "2021-10-11T11:30:23.105698Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.105680Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the train data\n",
    "train_pred_nb = nb.predict(X_train)\n",
    "\n",
    "# Calculate the f1 score on the train set\n",
    "f1_score_train_nb = f1_score(y_train,train_pred_nb, average = \"weighted\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.106688Z",
     "iopub.status.idle": "2021-10-11T11:30:23.107272Z",
     "shell.execute_reply": "2021-10-11T11:30:23.107103Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.107086Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict of the train set\n",
    "train_pred_nb_smote = nb_smote.predict(X_train)\n",
    "\n",
    "# Calculate the f1 score on the train set\n",
    "f1_score_train_nb_smote = f1_score(y_train,train_pred_nb_smote, average = \"weighted\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.107977Z",
     "iopub.status.idle": "2021-10-11T11:30:23.108565Z",
     "shell.execute_reply": "2021-10-11T11:30:23.108393Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.108375Z"
    }
   },
   "outputs": [],
   "source": [
    " \n",
    "    \"\"\"\n",
    "    Create a dataframe to show the \n",
    "    f1 score of the basic models vs the smote models\n",
    "    \n",
    "    \"\"\"\n",
    "# Create a list of f1 scores\n",
    "f1_scores_pred = [f1_score_logreg, \n",
    "                  f1_score_logreg_smote, \n",
    "                  f1_score_svm,\n",
    "                  f1_svm_CV_smote, \n",
    "                  f1_nb,\n",
    "                  f1_nb_smote]\n",
    "\n",
    "#Create a list train f1_score\n",
    "f1_scores_train = [f1_score_train_logreg, f1_score_train_logreg_smote, \n",
    "                    f1_score_train_svm, f1_score_train_svm_smote,\n",
    "                    f1_score_train_nb,  f1_score_train_nb_smote]\n",
    "\n",
    "# Create a list to use as row labels\n",
    "models2 = [\"LogisticRegression\", \"LogisticRegression (with SMOTE)\",\n",
    "          \"Support Vector Machine\", \"Support Vector Machine(with SMOTE)\",\n",
    "          \" Multinomial_NB\", \"Multinomial_NB(with SMOTE)\"] \n",
    "\n",
    "# Create a dictionary of the the f1 scores \n",
    "f1_scores_dict = {'model': models,\n",
    "                  'f1_score_train': f1_scores_train,\n",
    "                  'f1_score_pred' : f1_scores_pred,\n",
    "                  }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the dataframe\n",
    "models_df = pd.DataFrame.from_dict(f1_scores_dict)\n",
    "\n",
    "#setting the index\n",
    "models_df = models_df.set_index('model')\n",
    "\n",
    "\n",
    "# Display the first 5 rows of the new dataframe\n",
    "models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1_score analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.109296Z",
     "iopub.status.idle": "2021-10-11T11:30:23.109833Z",
     "shell.execute_reply": "2021-10-11T11:30:23.109642Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.109615Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot a bargraph from the data \n",
    "models_df.plot.barh(color={\"f1_score_train\": \"red\", \"f1_score_pred\": \"green\"},figsize = (15,10)).legend( title=\"Index\", \n",
    "                    ncol= 2,\n",
    "                    prop={'size': 11})\n",
    "plt.title(\"F1 scores for each model compared to Train Data set\") # Set title\n",
    "plt.xlabel(\"Models\") # Set x label\n",
    "plt.ylabel(\"F1 score\")# Set y label\n",
    "plt.show() # plot the graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.111104Z",
     "iopub.status.idle": "2021-10-11T11:30:23.111946Z",
     "shell.execute_reply": "2021-10-11T11:30:23.111742Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.111718Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc #import the necessary metrics\n",
    "\"\"\"\n",
    "    This function is to find the ROC_AUC curve and AUC.\n",
    "    This function also plots the necessary plots.\n",
    "    Takes in the function(clf), Validations sets(X_test,y_test), number of classes(n_classes) , \n",
    "    size of your figure(figsize= tuple of integers) and a figure as ax = none \n",
    "\"\"\"\n",
    "\n",
    "def plot_multiclass_roc(clf, X_test, y_test, n_classes, figsize=(17, 6), ax = None):\n",
    "    y_score = clf.predict_proba(X_test) #perform a decision_test function\n",
    "\n",
    "    # Create empty dictionary for the structures\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # calculate dummies once\n",
    "    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "    \n",
    "    # Loop through classes to get the FPR,TPR\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:,i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # Instatiate a graph\n",
    "    if(ax is None):\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "     #  plot the roc for each class \n",
    "    ax.plot(fpr[0], tpr[0], label= f'ROC curve (area = {roc_auc[0]:.2f}) for Class 2')\n",
    "    ax.plot(fpr[1], tpr[1], label=f'ROC curve (area = {roc_auc[1]:.2f}) for Class -1')    \n",
    "    ax.plot(fpr[2], tpr[2], label=f'ROC curve (area = {roc_auc[2]:.2f}) for Class 0')\n",
    "    ax.plot(fpr[3], tpr[3], label=f'ROC curve (area = {roc_auc[3]:.2f}) for Class 1')\n",
    "    \n",
    "  \n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0]) # set x \n",
    "    ax.set_ylim([0.0, 1.05])# set y\n",
    "    ax.set_xlabel('False Positive Rate') # Set x label\n",
    "    ax.set_ylabel('True Positive Rate') # Set y label\n",
    "    ax.legend(loc=\"best\") # Set legend postion\n",
    "    \n",
    "    ax.grid(alpha=.4)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOGISTIC REGRESSION CLASSIFIER**\n",
    "\n",
    "**ROC AUC CURVE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.113027Z",
     "iopub.status.idle": "2021-10-11T11:30:23.113388Z",
     "shell.execute_reply": "2021-10-11T11:30:23.113226Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.113204Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,15))                  # Changed the size of the figure, just aesthetic\n",
    "ax1 = fig.add_subplot(1,2,1)     # Change the subplot arguments\n",
    "plot_multiclass_roc(logreg, X_val, y_val, n_classes=4, figsize=(5, 5),ax = ax1)\n",
    "ax2 = fig.add_subplot(1,2,2)                        # Change the subplot arguments\n",
    "plot_multiclass_roc(logreg_smote, X_val, y_val, n_classes=4, figsize=(5, 5),ax = ax2)\n",
    "ax1.set_title(\"The Receiver operating characteristics of the Logistic Regression classifier with no SMOTE\")\n",
    "ax2.set_title(\"The Receiver operating characteristics of the Logistic Regression classifier with SMOTE\")\n",
    "plt.gcf().set_size_inches(20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLASS PREDICTION ERROR** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.114863Z",
     "iopub.status.idle": "2021-10-11T11:30:23.115343Z",
     "shell.execute_reply": "2021-10-11T11:30:23.115111Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.115086Z"
    }
   },
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import  ClassPredictionError\n",
    "# Instantiate the classification model and visualizer\n",
    "logreg_class = ClassPredictionError(\n",
    "    logreg, classes=[-1,0,1,2]\n",
    ")\n",
    "\n",
    "# Fit the training data to the visualizer\n",
    "logreg_class.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "logreg_class.score(X_val, y_val)\n",
    "\n",
    "# Draw visualization\n",
    "logreg_class.show()\n",
    "logreg_class_smote = ClassPredictionError(\n",
    "    logreg_smote, classes=[-1,0,1,2]\n",
    ")\n",
    "\n",
    "# Fit the training data to the visualizer\n",
    "logreg_class_smote.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "logreg_class_smote.score(X_val, y_val)\n",
    "\n",
    "# Draw visualization\n",
    "logreg_class_smote.show()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUPPORT VECTOR MACHINE**\n",
    "\n",
    "**CLASS PREDICTION ERROR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.116676Z",
     "iopub.status.idle": "2021-10-11T11:30:23.117180Z",
     "shell.execute_reply": "2021-10-11T11:30:23.116947Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.116922Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the classification model and visualizer\n",
    "SVM_class = ClassPredictionError(\n",
    "    svm_clf, classes=[-1,0,1,2]\n",
    ")\n",
    "\n",
    "# Fit the training data to the visualizer\n",
    "SVM_class.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "SVM_class.score(X_val, y_val)\n",
    "\n",
    "# Draw visualization\n",
    "SVM_class.show()\n",
    "\n",
    "# Instantiate the classification model and visualizer\n",
    "SVM_class_smote = ClassPredictionError(\n",
    "    svm_clf_CV_smote, classes=[-1,0,1,2]\n",
    ")\n",
    "\n",
    "# Fit the training data to the visualizer\n",
    "SVM_class_smote.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "SVM_class_smote.score(X_val, y_val)\n",
    "\n",
    "# Draw visualization\n",
    "SVM_class_smote.show()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes Multinomial NB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.119175Z",
     "iopub.status.idle": "2021-10-11T11:30:23.119473Z",
     "shell.execute_reply": "2021-10-11T11:30:23.119339Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.119324Z"
    }
   },
   "outputs": [],
   "source": [
    "fig3 = plt.figure(figsize = (8,15))                  \n",
    "ax5 = fig3.add_subplot(1,2,1)     # Change the subplot arguments\n",
    "plot_multiclass_roc(nb, X_val, y_val, n_classes=4, figsize=(5, 5),ax = ax5)\n",
    "ax6 = fig3.add_subplot(1,2,2)                        # Change the subplot arguments\n",
    "plot_multiclass_roc(nb_smote, X_val, y_val, n_classes=4, figsize=(5, 5),ax = ax6) # Call the plot function\n",
    "ax5.set_title(\"The Receiver operating characteristics of the Naive Bayes Multinomial NB classifier with no SMOTE\")\n",
    "ax6.set_title(\"The Receiver operating characteristics of the Naive Bayes Multinomial NB classifier with SMOTE\")\n",
    " \n",
    "plt.gcf().set_size_inches(20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.120950Z",
     "iopub.status.idle": "2021-10-11T11:30:23.121485Z",
     "shell.execute_reply": "2021-10-11T11:30:23.121286Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.121258Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the classification model and visualizer\n",
    "NB_class = ClassPredictionError(\n",
    "    nb, classes=[-1,0,1,2]\n",
    ")\n",
    "\n",
    "# Fit the training data to the visualizer\n",
    "NB_class.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "NB_class.score(X_val, y_val)\n",
    "\n",
    "# Draw visualization\n",
    "NB_class.show()\n",
    "NB_class_smote = ClassPredictionError(\n",
    "    nb_smote, classes=[-1,0,1,2]\n",
    ")\n",
    "\n",
    "# Fit the training data to the visualizer\n",
    "NB_class_smote.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "NB_class_smote.score(X_val, y_val)\n",
    "\n",
    "# Draw visualization\n",
    "NB_class_smote.show()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. Overiew findings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2021-10-11T11:30:23.122478Z",
     "iopub.status.idle": "2021-10-11T11:30:23.122831Z",
     "shell.execute_reply": "2021-10-11T11:30:23.122682Z",
     "shell.execute_reply.started": "2021-10-11T11:30:23.122659Z"
    }
   },
   "outputs": [],
   "source": [
    "* The Logistic Regression performed well compared to its other counterpart producing an f1_score of 0.74 as well as the accuracy score of 0.75.\n",
    "* Reasons:\n",
    "* The data was linearly separable even though it was multiclassed. \n",
    "* Logistic Regression Performs optimally when classified the data is balanced and when there is two classes and assumes that the data is linearly separable.\n",
    "* The use of the one vs rest technique allowed to do the classification more simply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
